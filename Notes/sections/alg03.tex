 \subsection{GSVD algorithm} \label{alg}
The algorithm consists of four steps. First step 
is a pre-processing step where the input matrix pair is
reduced to a triangular pair while revealing their ranks~\cite{bai1993new}.
We further reduce two upper triangular matrices to one upper triangular matrix in the QR decomposition step. Next is the CS decomposition of a matrice with orthonormal columns that is partitioned into two blocks. \cite{van1976generalizing} The last step is post-processing to get the final product of the decomposition. 
    
\paragraph{Step 1. Pre-processing:}
To reduce ``regular matrices to their triangular form and reveal rank'', 
we employ the QR decomposition with column pivoting followed by 
RQ decomposition \cite{golub2013matrix} as well as QR decomposition. 
We detail this in nine substeps below.
            
\begin{enumerate}[(1)]
\item QR decomposition with column pivoting of $B$:
\[
BP = V\bordermatrix{ & \ell & n-\ell \cr
\hfill \ell & B_{11} & B_{12} \cr
\hfill p-\ell & 0 & 0 \cr}
\]

\item Update $A := AP$
\item Set $Q := I_n$ and update $Q := QP$

\item If $n > \ell$:
\begin{itemize}
\item RQ decomposition of $(B_{11} \ \ B_{12})$:
\[
\bordermatrix{ & \ell & n-\ell \cr
\hfill \ell & B_{11} & B_{12} \cr}
= \bordermatrix{ & n-\ell & \ell \cr
\hfill \ell & 0 & B_{13} \cr}Z
\]
\item Update $A := AZ^{T}$
\item Update $Q := QZ^{T}$
\end{itemize}

\item Partition
\[
A = \bordermatrix{ & n-\ell & \ell \cr
\hfill m & A_{1} & A_{2} \cr},
\]
the QR decomposition with column pivoting of $A_1$ is:
\[
A_{1}P_{1} = 
U\bordermatrix{ & k & n-\ell-k \cr
\hfill k & A_{11} & A_{12} \cr
\hfill m-k & 0 & 0 \cr}
\]
\item Update $A_{2} := U^{T}A_{2}$ 

\item Partition 
$A = \bordermatrix{ 
           & k & n-\ell-k & \ell \cr
\hfill k   & A_{11} & A_{12} & A_{13} \cr
\hfill m-k & 0      & 0      & A_{23} \cr}$

\item Update $Q(:, 1:n-\ell) := Q(:, 1:n-\ell)P_{1}$

\item If $n-\ell > k$:
\begin{itemize}
\item RQ decomposition of $(A_{11} \ \ A_{12})$:
\[
\bordermatrix{ & k & n-\ell-k \cr
\hfill k & A_{11} & A_{12} \cr}
= \bordermatrix{ & n-\ell-k & k \cr
\hfill k & 0 & A_{12} \cr}Z_{1}
\]
and it results 
$A = \bordermatrix{ 
           & n-\ell-k & k  & \ell \cr
\hfill k   & 0 & A_{12} & A_{13} \cr
\hfill m-k & 0      & 0      & A_{23} \cr}$


\item Update $Q(:,1:n-\ell) = Q(:, 1:n-\ell) Z_{1}^{T}$
\end{itemize}

\item If $m > k$:

Let 
\[
A_{2} = \bordermatrix{ & \ell  \cr
\hfill k & A_{13}  \cr
\hfill m-k & A_{23} \cr}
\]
\begin{itemize}
\item QR decomposition of $A_{23}$:
\[
A_{23} = U_{1}\bordermatrix{ & \ell  \cr
\hfill \ell & A_{23}  \cr
\hfill m-k-\ell & 0 \cr}
\]
\item Update $U(:,k+1:m) = U(:,k+1:m)U_{1}$
\end{itemize}    
\end{enumerate}
In summary, we have the following decomposition at the end of the
pre-processing: 
\begin{equation} \label{eq-alg-1}
A = UR_{A}Q^{T},\ \ \ \ B = VR_{B}Q^{T}
\end{equation}
where
\begin{itemize}
\item If $m-k-\ell \geq 0$: 
\[
R_{A} = \bordermatrix{ & n-k-\ell & k & \ell \cr
\hfill k & 0 & A_{12} & A_{13} \cr
\hfill \ell & 0 & 0 & A_{23} \cr
\hfill m-k-\ell & 0 & 0 & 0}, \  \ \ \
R_{B} = \bordermatrix{ & n-k-\ell & k & \ell   \cr
\hfill \ell & 0 & 0 & B_{13}\cr
\hfill p-\ell & 0 & 0 & 0}
\]
where $R_A$ and $R_B$ overwrite $A$ and $B$, respectively, and 
$A_{12}$ and $B_{13}$ are non-singular upper triangular matrix. 
$\ell$ is the rank of $B$, $k+\ell$ is the rank of $[A^T \ B^T]^T$. 
$A_{23}$ is $\ell$-by-$\ell$ upper triangular, 

\item If $m-k-\ell < 0$:
\[
R_{A} = \bordermatrix{ & n-k-\ell & k & \ell \cr
\hfill k & 0 & A_{12} & A_{13} \cr
\hfill m-k & 0 & 0 & A_{23}}, \  \ \ \
R_{B} = \bordermatrix{ & n-k-\ell & k & \ell   \cr
\hfill \ell & 0 & 0 & B_{13}\cr
\hfill p-\ell & 0 & 0 & 0}, 
\]
where $R_A$ and $R_B$ overwrite $A$ and $B$, respectively, and 
$A_{12}$ and $B_{13}$ are non-singular upper triangular matrix. 
$\ell$ is the rank of $B$, $k+\ell$ is the rank of $[A^T \ B^T]^T$. 
$A_{23}$ is $(m-k)$-by-$\ell$ upper trapezoidal. 
\end{itemize}        

\paragraph{Step 2. QR decomposition of $[A_{23}^{T} \ B_{13}^{T}]^T$:} 

    \begin{itemize}
    	\item If $m-k-\ell \geq 0$:
	    	\[
                \bordermatrix{ & \ell  \cr
                    \hfill \ell & A_{23}  \cr
                    \hfill \ell & B_{23} \cr} = 
                \bordermatrix{ & \ell  \cr
                    \hfill \ell & Q_{1}  \cr
                    \hfill \ell & Q_{2} \cr}R_{23}   
        	\]
    	\item If $m-k-\ell < 0$:  
			\[
                \bordermatrix{ & \ell  \cr
                    \hfill m-k & A_{23}  \cr
                    \hfill \ell & B_{23} \cr} = 
                \bordermatrix{ & \ell  \cr
                    \hfill m-k & Q_{1}  \cr
                    \hfill \ell & Q_{2} \cr}R_{23}   
        	\]          
    \end{itemize}
            Thus, \eqref {eq-alg-1} can be rewritten as:
            \begin{equation} \label{eq-alg-2}
                A = U(Q_{A}\hat{R})Q^{T}, \ \ \ \ B = V(Q_{B}\hat{R})Q^{T}
            \end{equation}
            where 
            \begin{itemize}
            	\item If $m-k-\ell \geq 0$:
					\[
                        Q_{A} = \bordermatrix{ & k & \ell \cr
                        \hfill k & I & 0 \cr
                        \hfill \ell & 0 & Q_1 \cr
                        \hfill m-k-\ell & 0 & 0}, \  \ \ \
                        Q_{B} = \bordermatrix{ & k & \ell   \cr
                        \hfill \ell & 0 & Q_2\cr
                        \hfill p-\ell & 0 & 0}, \ \ \ \
                        \hat{R} = \bordermatrix{ & n-k-\ell & k & \ell \cr
                        \hfill k & 0 & A_{12} & B_{13} \cr
                        \hfill \ell & 0 & 0 & R_{23}}
            		\]
				\item If $m-k-\ell < 0$:  
					\[
                        Q_{A} = \bordermatrix{ & k & \ell \cr
                        \hfill k & I & 0 \cr
                        \hfill m-k & 0 & Q_1}, \  \ \ \
                        Q_{B} = \bordermatrix{ & k & \ell   \cr
                        \hfill \ell & 0 & Q_2\cr
                        \hfill p-\ell & 0 & 0}, \ \ \ \
                        \hat{R} = \bordermatrix{ & n-k-\ell & k & \ell \cr
                        \hfill k & 0 & A_{12} & B_{13} \cr
                        \hfill \ell & 0 & 0 & R_{23}}
            		\]
            \end{itemize}
        
\paragraph{Step 3. CS decomposition of $Q_1$ and $Q_2$:}

\begin{align} \label{eq-alg-3}
Q_1 = U_1\Sigma_{1}Z_1^{T}, \ \ \ \ 
Q_2 = V_1\Sigma_{2}Z_1^{T}
\end{align}
where
\begin{itemize}
\item If $m-k-\ell \geq 0$:

$U_{1}$, $Z_{1}$ and $V_{1}$ are $\ell$-by-$\ell$ orthogonal
matrices, and $\Sigma_{1}$ and $\Sigma_{2}$ are $\ell$-by-$\ell$ diagonal matrices,
and $\Sigma_{1}^{T}\Sigma_{1} + \Sigma_{2}^{T}\Sigma_{2} = I_{\ell}$.

\item If $m-k-\ell < 0$:

$U_{1}$ is $(m-k)$-by-$(m-k)$ orthogonal and 
$Z_{1}$ and $V_{1}$ are $\ell$-by-$\ell$ orthogonal. 
$\Sigma_{1}$ is $(m-k)$-by-$\ell$ diagonal, 
$\Sigma_{2}$ is $\ell$-by-$\ell$ diagonal 
and $\Sigma_{1}^{T}\Sigma_{1} + \Sigma_{2}^{T}\Sigma_{2} = I_{\ell}$.
\end{itemize}

Combining \eqref{eq-alg-2} and \eqref{eq-alg-3} , we have

\begin{equation} \label{eq-alg-4}
A = U(\hat{U}C\hat{Q}^{T})\hat{R}Q^{T}, \ \ \ \ 
B = V(\hat{V}S\hat{Q}^{T})\hat{R}Q^{T}
\end{equation}
where
\begin{itemize}
\item If $m-k-\ell \geq 0$:
	\[
                \hat{U} = \bordermatrix{ & k & \ell & m-k-\ell\cr
                \hfill k & I & 0 & 0\cr
                \hfill \ell & 0 & U_1 & 0\cr
                \hfill m-k-\ell & 0 & 0 & I}, \  \ \ \
                \hat{V} = \bordermatrix{ & \ell & p-\ell   \cr
                \hfill \ell & V_1 & 0\cr
                \hfill p-\ell & 0 & I}, \ \ \ \
                \hat{Q}^{T} = \bordermatrix{ & k & \ell   \cr
                \hfill \ell & I & 0\cr
                \hfill p-\ell & 0 & Z_1^{T}}
     \]
     and 
     \[
                C = \bordermatrix{ & k & \ell \cr
                \hfill k & I & 0 \cr
                \hfill \ell & 0 & \Sigma_{1} \cr
                \hfill m-k-\ell & 0 & 0}, \  \ \ \
                S = \bordermatrix{ & k & \ell   \cr
                \hfill \ell & 0 & \Sigma_{2}\cr
                \hfill p-\ell & 0 & 0}
    \]
\item If $m-k-\ell < 0$:
	\[
                \hat{U} = \bordermatrix{ & k & m-k \cr
                \hfill k & I & 0 \cr
                \hfill m-k & 0 & U_1}, \  \ \ \
                \hat{V} = \bordermatrix{ & \ell & p-\ell   \cr
                \hfill \ell & V_1 & 0\cr
                \hfill p-\ell & 0 & I}, \ \ \ \
                \hat{Q}^{T} = \bordermatrix{ & k & \ell   \cr
                \hfill \ell & I & 0\cr
                \hfill p-\ell & 0 & Z_1^{T}}
     \]
     and 
     \[
                C = \bordermatrix{ & k & \ell \cr
                \hfill k & I & 0 \cr
                \hfill m-k & 0 & \Sigma_{1}}, \  \ \ \
                S = \bordermatrix{ & k & \ell   \cr
                \hfill \ell & 0 & \Sigma_{2}\cr
                \hfill p-\ell & 0 & 0}
    \]
\end{itemize}

The algorithm for computing the CS decomposition is in Section \ref{csd}. 
        
\paragraph{Step 4. Post-processing:} 
\begin{itemize}
\item $U := U \hat{U}$.
\item $V := V \hat{V}$.
\item Formulate $R$ by RQ decomposition: $\hat{Q}^{T}\hat{R} = RQ_{3}$ 
\item $Q := Q Q_{3}^{T}$
\end{itemize}
Then we obtain the desired GSVD \eqref{eq:gsvdbylapack}, i.e., 
\begin{equation} \label{eq-alg-4}
A = UCRQ^{T}, \ \ \ \ 
B = VSRQ^{T}
\end{equation}
where $C$ and $S$ have the following structures:
    \begin{itemize}
        \item If $m - k - \ell \geq 0$:
            \begin{displaymath}
                C = \bordermatrix{ & k & \ell  \cr
                \hfill k & I & 0 \cr
                \hfill \ell & 0 & \Sigma_1 \cr
                m-k-\ell & 0 & 0}, \  \ \ \
                S = \bordermatrix{ & k & \ell \cr
                \hfill \ell & 0 & \Sigma_2 \cr
                \hfill p-\ell & 0 & 0}
            \end{displaymath}
                
        \item If $m - k - \ell < 0$:
            \begin{displaymath}
                C = \bordermatrix{ & k & m-k & k+\ell-m  \cr
                \hfill k & I & 0 & 0\cr
                \hfill m-k & 0 & \Sigma_1 & 0}, \  \ \ \
                S = \bordermatrix{ & k & m-k & k+\ell-m \cr
                \hfill m-k & 0 & \Sigma_2 & 0\cr
                \hfill k+\ell-m & 0 & 0 & I\cr
                \hfill p-\ell & 0 & 0 & 0}
            \end{displaymath}
    \end{itemize}
    In either case, $\Sigma_1^2 + \Sigma_2^2 = I$.
    
\begin{remark}
{\rm 
Michael Stewart \cite{stewart2016rank} describes 
an alternative rank revealing mechanism of $[A; B]$ 
and claims that it can more reliably determine 
the partitioning of a GSVD and shows improved numerical reliability.
} \end{remark} 

\begin{remark}
{\rm The algorithm presented here is ``similar to'' ...  
Golub and Van Loan \cite[pp.~502--503]{golub2013matrix} 
introduced an algorithm to compute GSVD using CS decomposition for tall, full-rank matrix pairs.

Assume that $A$ is $m$-by-$n$ and $B$ is $p$-by-$n$ with $m \geq n$ and $p \geq n$, computes an $m$-by-$m$ orthogonal matrix $U$, a $p$-by-$p$ orthogonal matrix $V$, an $n$-by-$n$ nonsingular matrix $X$ and $m$-by-$n$ diagonal matrice $C$, $p$-by-$n$ diagonal matrice $S$ such that $U^{T}AX = C$ and $V^{T}BX = S$.
\begin{enumerate}[\textit{Step} 1]
\item Compute the regular QR decomposition of $\begin{pmatrix} A\\ B\end{pmatrix}$:
        $\begin{pmatrix}
        A \\
        B
       \end{pmatrix}  = \begin{pmatrix}
        Q_1 \\
        Q_2
       \end{pmatrix}R$

       \item Compute the CS decomposition of $Q_1$ and $Q_2$:

        $U^{T}Q_1Z = C = diag(\alpha_i, \cdots, \alpha_n)$,
        $V^{T}Q_2Z = S = diag(\beta_i, \cdots, \beta_n)$·

        \item Solve $RX = Z$ for $X$.
    \end{enumerate}
}\end{remark} 

\begin{remark} 
{\rm 
LAPACK GSVD  algorithm \cite[pp.~51--53]{anderson1999lapack} has two phases.  First is a pre-processing step as described in Section \ref{alg}. 
Next is a {\bf Jacobi-style method} 
\cite{paige1986computing,bai1993computing} to compute the GSVD 
of two square upper trangular matrices, namely, 
$A_{23}$ and $B_{13}$ in \eqref{eq-alg-1} such that
\begin{equation} \label{eq-alg-jacobi}
A_{23} = U_1CRQ_1^{T},\ \ \ \ B_{13} = V_1SRQ_1^{T}.
\end{equation}
Here $U_1$, $V_1$ and $Q_1$ are orthogonal matrices, $C$ and $S$ are 
both real nonnegative matrices satisfying $C^TC + S^TS = I$, 
$S$ is nonsingular, and $R$ is upper triangular and nonsingular.
} \end{remark} 

%-----------------------
    
\subsection{CS Decomposition} \label{csd}

\subsubsection{Definition}
Suppose we have an $(m+p)-by-n$ matrix $Q$ such that $m+p \geq n$ and has orthonormal columns. If we partition $Q$ into 2-by-1 form as $[Q_1; Q_2]$, then the CS decomposition of $Q_1$ and $Q_2$ is the following:
    \begin{align}
        Q_1 = UCZ^T,\ \  \ \ Q_2 = VSZ^T
    \end{align}
where 
    \begin{itemize}
        \item $U$ is $m$-by-$m$, $V$ is $p$-by-$p$, 
             and $Z$ is $n$-by-$n$, all are orthogonal. 
        \item $C$ is $m$-by-$n$ real non-negative diagonal,
              and $S$ is $p$-by-$n$ real non-negative with 
                  the top right diagonal block, and 
        $C^{T}C + S^{T}S = I$. 

%Write $C^{T}C = diag(\alpha_1^{2}, \alpha_2^{2}, \cdots, \alpha_n^{2})$ 
%and $S^{T}S = diag(\beta_1^{2}, \beta_2^{2}, \cdots, \beta_n^{2})$, 
%we have 
%\begin{align} \label{cosine-sine}
%\alpha_i^{2} + \beta_i^{2} = 1 \ \  \text{for} \ \ i = 1,2,\cdots,n
%\end{align}

$C$ and $S$ have the following detailed structures: 
\begin{enumerate}
        \item $m \geq n$ and $p \geq n$:
        \begin{displaymath}
            C = \bordermatrix{ & n  \cr
            \hfill n & \Sigma_1 \cr
            \hfill m-n & 0}, \  \ \ \
            S = \bordermatrix{ & n \cr
            \hfill n & \Sigma_2 \cr
            \hfill p-n & 0}
        \end{displaymath}
        
        \item $m \geq n$ and $p < n$:
        \begin{displaymath}
            C = \bordermatrix{ & n-p & p  \cr
            \hfill n-p & I & 0 \cr
            \hfill p & 0 & \Sigma_1 \cr
            \hfill m-n & 0 & 0}, \  \ \ \
            S = \bordermatrix{ & n-p & p\cr
            \hfill p & 0 & \Sigma_2}
        \end{displaymath}
        
        \item $m \leq n$ and $p \geq n$:
        \begin{displaymath}
            C = \bordermatrix{ & m & n-m\cr
            \hfill m & \Sigma_1 & 0}, \  \ \ \
            S = \bordermatrix{ & m & n-m  \cr
            \hfill m & \Sigma_2 & 0 \cr
            \hfill n-m & 0 & I \cr
            \hfill p-n & 0 & 0}
        \end{displaymath}
        
        \item $m \leq n$ and $p < n$:
        \begin{displaymath}
            C = \bordermatrix{ & n-p & t & n-m \cr
            \hfill n-p & I & 0 & 0 \cr
            \hfill t & 0 & \Sigma_1 & 0}, \  \ \ \
            S = \bordermatrix{ & n-p & t & n-m \cr
            \hfill t & 0 & \Sigma_2 & 0 \cr
            \hfill n-m & 0 & 0 & I}
        \end{displaymath}
        where $t = m+p-n$.
    \end{enumerate}
where $\Sigma_1$ and $\Sigma_2$ are diagonal matrices 
and satisfy $\Sigma_1^2 + \Sigma_2^2 = I$.
\end{itemize} 

\paragraph{Why called the CSD?}
Write $C^{T}C = diag(\alpha_1^{2}, \alpha_2^{2}, \cdots, \alpha_n^{2})$ 
and $S^{T}S = diag(\beta_1^{2}, \beta_2^{2}, \cdots, \beta_n^{2})$, 
we have 
\begin{align} \label{cosine-sine}
\alpha_i^{2} + \beta_i^{2} = 1 \ \  \text{for} \ \ i = 1,2,\cdots,n
\end{align}
CS decomposition is named after cosine and sine due to the 
resemblance between \eqref{cosine-sine} and cosine-sine relation. Thus, we name $\alpha_i$ and $\beta_i$ cosine and sine values, respectively. To align with the growth of cosine and sine values between angles of 0 and $\frac{\pi}{2}$ in Euclidean geometry, $\alpha_i$ are placed in non-increasing order while $\beta_i$ are sorted in non-decreasing order. 

\begin{remark}
{\rm  
LAPACK provides a routine to compute the CSD of 
a 2-by-1 partitioned matrix, which is developed 
by Sutton \cite{sutton2009computing}.  
    
Given an $(m+p)$-by-$n$ matrix $X$ with orthonormal columns that has been partitioned into a 2-by-1 block structure: 
        \begin{displaymath}
            X = \bordermatrix{ & n  \cr
            \hfill m & X_1 \cr
            \hfill p & X_2}
        \end{displaymath}
    There exist a $m$-by-$m$ matrix $U_1$, an ($p$)-by-($p$) matrix $U_2$, and a $n$-by-$n$ matrix $V_1$ (all are orthogonal) such that:
        \begin{displaymath}
            \begin{pmatrix}
                U_1 & 0 \\
                0 & U_2
            \end{pmatrix}^{T}
            \begin{pmatrix}
                X_1 \\
                X_2
            \end{pmatrix}V_1 = 
            \begin{pmatrix}
                I_1 & 0 & 0 \\
                0 & C & 0 \\
                0 & 0 & 0 \\
                \cline{1-3} 
                0 & 0 & 0 \\
                0 & S & 0 \\
                0 & 0 & I_2
            \end{pmatrix}
        \end{displaymath}
    where $C$ and $S$ are $r$-by-$r$ non-negative diagonal matrices satisfying $C^2 + S^2 = I$, in which $r = min\{m,p,n,m+q-n\}$. $I_1$ is a $k_1$-by-$k_1$ identity matrix and $I_2$ is a $k_2$-by-$k_2$ identity matrix, where $k_1 = max\{n-p,0\}$, $k_2 = max\{n-m,0\}$.
}\end{remark} 

\subsubsection{Algorithm} 
Now, we present an algorithm to compute the CS decomposition. 
The algorithm extends the one proposed by Van Loan \cite{vanloan85}.    
    
First, we set $q_1 = \min\{m, n\}$ and $q_2 = \min\{p, n\}$. 
We split this algorithm into two cases: $m \leq p$ and $m > p$.
    
\begin{enumerate}
\item If $m \leq p$:
\begin{enumerate}[\textit{Step} 1.]
\item SVD of $Q_2$ such that:
\begin{equation}
Q_2 = VSZ^{T}, 
\end{equation}
where $V$ is $p$-by-$p$, $Z$ is $n$-by-$n$, both are orthogonal matrices. 
$S$ has the following structure:
\begin{displaymath}
S = \bordermatrix{ & q_2 & n-q_2 \cr
\hfill q_2 & \Sigma & 0 \cr
\hfill p-q_2 & 0 & 0}
\end{displaymath}
where $\Sigma = \mbox{diag}(\beta_n, \cdots, \beta_{n-q_2+1})$ 
such that 
$1 \geq \beta_n \geq \beta_{n-1} \geq \cdots \geq \beta_{n-q_2+1} \geq 0$. 

This means we need to reverse the order of $\beta_{i}$ to preserve that the sine values are in non-decreasing order. Thus,
\begin{itemize}
\item Reorder the diagonal entries of $S$ in non-decreasing, such that:
\begin{displaymath}
S = \bordermatrix{ & n-q_2 & q_2 \cr
\hfill q_2 & 0 & \hat{\Sigma} \cr
\hfill p-q_2 & 0 & 0}
\end{displaymath} 
where $\hat{\Sigma} = \mbox{diag}(\beta_{n-q_2+1}, \cdots, \beta_{n})$
\item Reverse the first $q_2$ columns of $V$: $V(:,1:q_2) = V(:,q_2:-1:1)$. 
\item Reverse the columns of $Z$: $Z = Z(:,n:-1:1)$. 
\end{itemize}
                    
Since $Q_2$ has $(n-q_2)$ zero singular values, 
$\beta_{1} = \beta_{2} = \cdots = \beta_{n-q_2} = 0$ and 
correspondingly, $\alpha_1 = \alpha_2 = \cdots = \alpha_{n-q_2} = 1$.

\item Determine $r$ such that 
$0 \leq \beta_{n-q_2+1} \leq \cdots \leq \beta_{r} 
\leq \frac{1}{\sqrt{2}} \leq \beta_{r+1} \leq \cdots \leq \beta_{n} \leq 1$. 
                
%(\textcolor{red}{Footnote needed to justify the choice of 
%$\frac{1}{\sqrt{2}}$ as the threshold. Any suggestion on formatting? ...\
%depending on the length of justification, could be a footnote, 
%or a remark at the end of algorithm description})
                
\item $T = Q_1Z$.
\item QR decomposition of $T$:
\begin{equation}
T = UR,
\end{equation}
where $U$ is an $m$-by-$m$ orthogonal matrix,
\begin{equation} \label{eq-R-block-case1}
R = \bordermatrix{ & n-q_2 & r-n+q_2 & q_1-r & n-q_1 \cr
\hfill n-q_2 & I & \epsilon & \epsilon & \epsilon \cr
\hfill r-n+q_2 & 0 & R_{22} & \epsilon & \epsilon \cr
\hfill q_1-r & 0 & 0 & R_{33} & R_{34} \cr
\hfill m-q_1 & 0 & 0 & 0 & 0}
\end{equation}
and $R_{22} = \mbox{diag}(\alpha_{n-q_2+1}, \cdots, \alpha_{r})$.
                    
%(\textcolor{red}{Footnote needed to justify the near-zero block matrices 
%in the upper diagonal. This justification could be really long, 
%where is the proper place to put it?, a remark or subsection on technical
%details} ) 
                    
                    Combining \textit{Step} 3 and \textit{Step} 4, we obtain:
                    \begin{align} \label{eq-q_1-case1}
                        Q_1 = URZ^{T}
                    \end{align}
                    
                    The formula above can be treated as the SVD of $Q_1$. Thus, the fact that $Q_1$ has $(n-q_1)$ zero singular values implies that $\alpha_{q_1} = \cdots = \alpha_{l} = 0$, and $\beta_{q_1} = \cdots = \beta_{l} = 1$, respectively. 
                \item SVD of $(R_{33} \ R_{34})$ such that:
                    \begin{align} \label{eq-r-svd}
                        (R_{33} \ R_{34}) = U_{r}C_{r}Z_{r}^{T}
                    \end{align}   
                    where $U_{r}$ is a $(q_1-r)$-by-$(q_1-r)$ orthogonal matrix, $Z_{r}$ is an $(n-r)$-by-$(n-r)$ orthogonal matrix and $C_{r}$ is a $(q_1-r)$-by-$(n-r)$ matrix with the main diagonal entries storing non-zero $\alpha_{r+1}, \cdots, \alpha_{q_1}$.
                    \item To plug \eqref{eq-r-svd} into \eqref{eq-q_1-case1}, we shall update $U$, $R$ and $Z$ accordingly:
                        \begin{itemize}
                            \item Update the $(r+1)$ to $q_1$ columns of $U$:
                                \begin{displaymath}
                                    U = U\bordermatrix{ & r & q_1-r & m-q_1 \cr
                                    \hfill r & I & 0 & 0 \cr
                                    \hfill q_1-r & 0 & U_{r} & 0 \cr
                                    \hfill m-q_1 & 0 & 0 & I}
                                \end{displaymath}
                            \item Update the last $(n-r)$ columns of $Z$:
                                \begin{displaymath}
                                    Z = Z\bordermatrix{ & r & n-r \cr
                                    \hfill r & I & 0 \cr
                                    \hfill n-r & 0 & Z_{r}}
                                \end{displaymath}
                            \item Rewrite $R$ to formulate $C$:
                                \begin{displaymath}
                                    C = \bordermatrix{ & n-q_2 & r-n+q_2 & q_1-r & n-q_1 \cr
                                    \hfill n-q_2 & I & 0 & 0 & 0 \cr
                                    \hfill r-n+q_2 & 0 & R_{22} & 0 & 0 \cr
                                    \hfill q_1-r & 0 & 0 & C_{r}(:,1:q_1-r) & 0 \cr
                                    \hfill m-q_1 & 0 & 0 & 0 & 0}
                                \end{displaymath}
                        \end{itemize}
                    
                    Now, we have the final decomposition of $Q_1$:
                    \begin{align}
                        Q_1 = UCZ^{T}
                    \end{align}
                    \item Since $Z$ is updated, we need to modify $V$ as well:
                        \begin{itemize}
                            \item Set $W$:
                            
                                Let $S_1 = diag(\beta_{r+1}, \cdots, \beta_{q_2})$, $W = S_1Z_{r}(1:q_2-r,1:q_2-r)$.
                            \item QR decomposition of $W$:
                                \begin{align}
                                    W = Q_{w}R_{w}
                                \end{align}
                            \item Update middle $(q_2-r)$ columns of $V$:
                            
                                Let $l = min\{r, n-q_2\}$,
                                \begin{displaymath}
                                    V = V\bordermatrix{ & r-l & q_2-r & p-q_2+l \cr
                                    \hfill r-l & I & 0 & 0 \cr
                                    \hfill q_2-r & 0 & Q_{w} & 0 \cr
                                    \hfill p-q_2+l & 0 & 0 & I}
                                \end{displaymath}
                        \end{itemize}
            \end{enumerate}
            To summarize, we obtain:
            \begin{align}
                Q_1 = UCZ^{T}, \ \ \ \ Q_2 = VSZ^{T}
            \end{align}
            and
            \begin{displaymath}
                C = \bordermatrix{ & n-q_2 & t & n-q_1 \cr
                \hfill n-q_2 & I & 0 & 0 \cr
                \hfill t & 0 & \Sigma_1 & 0 \cr
                \hfill m-q_1 & 0 & 0 & 0}, \  \ \ \
                S = \bordermatrix{ & n-q_2 & t & n-q_1 \cr
                \hfill t & 0 & \Sigma_2 & 0 \cr
                \hfill n-m & 0 & 0 & I \cr
                \hfill p-q_2 & 0 & 0 & 0}
        \end{displaymath}
        where $t = q_1 + q_2 - n$, $\Sigma_1 = diag(\alpha_{l-q_2+1}, \cdots, \alpha_{q_1})$ and $\Sigma_2 = diag(\beta_{l-q_2+1}, \cdots, \beta_{q_1})$.
        
        \item If $m > p$:
            \begin{enumerate}[\textit{Step} 1.]
                \item Full SVD of $Q_1$ such that:
                    \begin{align}
                        Q_1 = UCZ^{T}
                    \end{align}
                    $U$ is $m$-by-$m$, $Z$ is $n$-by-$n$, both are orthogonal matrices. $C$ is $m$-by-$n$ with singular values $1 \geq \alpha_1 \geq \cdots \geq \alpha_{q_1} \geq 0$ placed in the main diagonal. Since $Q_1$ has $(n-q_1)$ zero singular values, we obtain $\alpha_{q_1+1} = \cdots = \alpha_{n} = 0$, and $\beta_{q_1+1} = \cdots = \beta_{n} = 1$, respectively. 
                \item Determine $r$ such that $1 \geq \alpha_{1} \geq \cdots \geq \alpha_{r} \geq \frac{1}{\sqrt{2}} \geq \alpha_{r+1} \geq \cdots \geq \alpha_{n} \geq 0$. 
                \item $T = Q_2Z$.
                \item QL decomposition of $T$:
                    \begin{align}
                        T = VL,
                    \end{align}
                    where $V$ is a $p$-by-$p$ orthogonal matrix, 
                    \begin{equation} \label{eq-L-block-case2}
                        L = \bordermatrix{ & n-q_2 & r & q_1+q_2-n-r & n-q_1 \cr
                                    \hfill p-q_2 & 0 & 0 & 0 & 0 \cr
                                    \hfill r & L_{11} & L_{12} & 0 & 0 \cr
                                    \hfill q_1+q_2-n-r & \epsilon & \epsilon & L_{23} & 0 \cr
                                    \hfill n-q_1 & \epsilon & \epsilon & \epsilon & I}
                    \end{equation}
                    and $L_{23} = diag(\beta_{n-q_2+r+1}, \cdots, \beta_{q_1})$.
                
                    To be consistent with the structure of $S$ given above, we pre-multiply $T$ with a permutation matrix $P$ in an effort to move the top $(n-q_2)$ rows to the bottom.
                    \begin{displaymath}
                        P = \bordermatrix{& p-q_2 & r & q_2-r \cr
                            \hfill r & 0 & I & 0 \cr
                            \hfill q_2-r & 0 & 0 & I \cr
                            \hfill p-q_2 & I & 0 & 0}
                    \end{displaymath}
                    Combining \textit{Step} 3 and \textit{Step} 4, we get:
                        \begin{align} \label{eq-q_2-case2}
                            Q_2 = V(P^{-1}PL)Z^{T}
                        \end{align}
                    This formula can be regarded as the SVD of $Q_2$. Therefore, the fact that $Q_2$ has $(n-q_2)$ zero singular values indicates that $\alpha_{1} = \cdots = \alpha_{n-q_2} = 1$, and $\beta_{1} = \cdots = \beta_{n-q_2} = 0$, respectively. 
                \item SVD of $(L_{11} \ L_{12})$ such that:
                    \begin{align} \label{eq-l-svd}
                        (L_{11} \ L_{12}) = V_{l}S_{l}Z_{l}^{T}
                    \end{align}
                    where $V_{l}$ is $r$-by-$r$ orthogonal matrix, $Z_{l}$ is $(n-q_2+r)$-by-$(n-q_2+r)$ orthogonal matrix and $S_{l}$ is $r$-by-$(n-q_2+r)$ and contains the $r$ singular values in a non-increasing fashion. However, by the nature of sine, we want to reverse the ordering of $\beta_i$. Accordingly, we need to reverse the columns of $V_{l}$ and $Z_{l}$.
                        \begin{itemize}
                            \item Reorder the diagonal entries of $S_{l}$ in non-decreasing order, such that:
                            \begin{displaymath}
                                S_{l} = \bordermatrix{ & r & n-q_2\cr
                                    \hfill r & \Sigma & 0}
                            \end{displaymath} where $\Sigma = diag(\beta_{n-q_2+1}, \cdots, \beta_{n-q_2+r})$
                            \item Reverse the columns of $V_l$: $V_l = V_l(:,r:-1:1)$. 
                            \item Reverse the columns of $Z_l$: $Z_l = Z_l(:,n-q_2+r:-1:1)$. 
                    \end{itemize} 
                \item To plug \eqref{eq-l-svd} into \eqref{eq-q_2-case2}, we shall update $V$, $L$ and $Z$ accordingly:
                    \begin{itemize}
                        \item Update $V$:
                            \begin{displaymath}
                                V = V\bordermatrix{ & p-q_2 & r & q_2-r \cr
                                    \hfill p-q_2 & I & 0 & 0 \cr
                                    \hfill r & 0 & U_{r} & 0 \cr
                                    \hfill q_2-r & 0 & 0 & I}P^{-1}
                            \end{displaymath}
                        \item Update the first ($r+n-q_2$) columns of $Z$:
                            \begin{displaymath}
                                Z = Z\bordermatrix{ & r+n-q_2 & q_2-r \cr
                                    \hfill r+n-q_2 & Z_{l} & 0 \cr
                                    \hfill q_2-r & 0 & I}
                            \end{displaymath}
                        \item Rewrite $L$ to formulate $S$:
                            \begin{displaymath}
                                S = \bordermatrix{ & n-q_2 & r & q_1+q_2-n-r & n-q_1 \cr
                                    \hfill r & 0 & S_{l}(:,1:r) & 0 & 0 \cr
                                    \hfill q_1+q_2-n-r & 0 & 0 & L_{23} & 0 \cr
                                    \hfill n-q_1 & 0 & 0 & 0 & I \cr
                                    \hfill p-q_2 & 0 & 0 & 0 & 0 }
                            \end{displaymath}
                    \end{itemize}
                \item Since $Z$ is updated, we need to modify $U$ as well:
                        \begin{itemize}
                            \item Set $W$:
                            
                                Let $C_1 = diag(\alpha_{1}, \cdots, \beta_{r+n-q_2})$, $W = C_1Z_{l}$.
                            \item QR decomposition of $W$:
                                \begin{align}
                                    W = Q_{w}R_{w}
                                \end{align}
                            \item Update $U$:
                                \begin{displaymath}
                                    U = U\bordermatrix{ & r+n-q_2 & m+r-l+q_2\cr
                                    \hfill r+n-q_2 & Q_{w} & 0 \cr
                                    \hfill m+r-l+q_2 & I & 0}
                                \end{displaymath}
                        \end{itemize}
            \end{enumerate}
    Putting all the 7 steps together, we have:
    \begin{align}
                Q_1 = UCZ^{T}, \ \ \ \ Q_2 = VSZ^{T}
            \end{align}
            and
            \begin{displaymath}
                C = \bordermatrix{ & n-q_2 & t & n-q_1 \cr
                \hfill n-q_2 & I & 0 & 0 \cr
                \hfill t & 0 & \Sigma_1 & 0 \cr
                \hfill m-q_1 & 0 & 0 & 0}, \  \ \ \
                S = \bordermatrix{ & n-q_2 & t & n-q_1 \cr
                \hfill t & 0 & \Sigma_2 & 0 \cr
                \hfill n-m & 0 & 0 & I \cr
                \hfill p-q_2 & 0 & 0 & 0}
        \end{displaymath}
        where $t = q_1 + q_2 - n$, $\Sigma_1 = diag(\alpha_{l-q_2+1}, \cdots, \alpha_{q_1})$ and $\Sigma_2 = diag(\beta_{l-q_2+1}, \cdots, \beta_{q_1})$.
    \end{enumerate}
    
\begin{remark}
{\rm
We justify here why we choose $\frac{1}{\sqrt{2}}$ as the threshold in \textit{Step} 2 of both cases. Since $Q_{1}^{T}Q_{1} + Q_{2}^{T}Q_{2} = I$ and $\Vert Q_{1}^{T}Q_{1} + Q_{2}^{T}Q_{2} \Vert_{1}$ = 1, the singular values of $Q_{1}$ and $Q_{2}$ lie between 0 and 1. $\frac{1}{\sqrt{2}}$ is the exact midpoint in between so that it nicely separates large singular values from tiny singular values. This theoretical yet empirical choice is first suggested by Van Loan in \cite{vanloan85} because the midpoint balances the backward error defined in \eqref{backward_error_1} - \eqref{backward_error_5} and performance.
}
\end{remark}

\begin{remark}
{\rm 
In \textit{Step} 4 of case 1, $R$ is upper triangular in exact arithmetics, but the upper-right 5 block matrices are effectively zero matrices. Here, we rationalize this assertion. 

If we analyse the $T$ matrix we computed in \textit{Step} 3, we have:
\begin{align*}
T^{T}T &= (Q_{1}Z)^{T}(Q_{1}Z) \\
	   &= Z^{T}Q_{1}^{T}Q_{1}Z \\
	   &= Z^{T}(I - Q_{2}^{T}Q_{2})Z \\
	   &= Z^{T}(I - ZS^{T}V^{T}VSZ^{T})Z \\
	   &= Z^{T}(I - ZS^{T}SZ^{T})Z \\
	   &= I - S^{T}S \\
	   &= diag(1-\beta_{1}^{2}, 1-\beta_{2}^{2}, \cdots, 1-\beta_{n}^{2}),
\end{align*}

which indicates that the norms of each column of $T$ are in non-increasing order. Further, it implies that $\sigma_{min}(T_{1}) \geq \sigma_{min}(T_{2}) \geq \cdots \geq \sigma_{min}(T_{r})$ where $T_{i}$ is the first $i$ columns of $T$ and $r$ = rank$(T)$. This can be proven by \textbf{Corollary 2.4.4} in \cite[pp.~78--78]{golub2013matrix} by Golub and Van Loan.

Before we proceed, we present the following theorem and its proof.

\begin{theorem}
Let $X$ be an $m$-by-$n$ matrix whose rank = $min(m, n)$ and
\begin{align*}
	X^{T}X = D^{T}D + E,
\end{align*}
where $\Vert E \Vert = O(\epsilon)$ and $D = diag(\Vert x_{1} \Vert, \Vert x_{2} \Vert, \cdots, \Vert x_{n} \Vert)$ and $x_{i}$ denotes the $i$-th column of $X$.

Applying the full QR decomposition of $X$, one obtains:
\begin{align}
	X = QR,
\end{align}
where $Q$ is an $m$-by-$m$ orthogonal matrix. $R$ is an $m$-by-$n$ upper triangular matrix if $m \geq n$. Otherwise, $R$ is upper trapezoidal. 

Let $X_{i}$ be the first $i$ columns of $X$, then for $i, j$ where $i < j \leq min(m, n)$, we have
\begin{align}
	\left|R(i, j)\right| \leq min\{\Vert x_{j} \Vert, \frac{\Vert E \Vert}{\sigma_{min}(X_{i})} \}.
\end{align}
\end{theorem}

\begin{proof}
This theorem is proved by Van Loan in \textbf{Theorem 3.2} \cite[pp.~484--485]{vanloan85}.
\end{proof}

From this theorem along with the $\frac{1}{\sqrt{2}}$ threshold we justified above, it follows that, for $i = 1, 2, \cdots, r$, 
\begin{align*}
	\left|R(i, j)\right| \leq \frac{\epsilon}{\sigma_{min}(T_{i})} \leq \frac{\epsilon}{\sqrt{1-\beta_{r}^{2}}} \leq \sqrt{2}\epsilon.
\end{align*}

By that, we know that $R(1:n-q_{2},n-q_{2}+1:r), R(1:n-q_{2},r+1:q_{1}), R(1:n-q_{2},q_{1}+1:n), R(n-q_{2}+1:r,r+1:q_{1})$ and $R(n-q_{2}+1:r,q_{1}+1:n)$, namely the 5 upper right block matrices of $R$ in \eqref{eq-R-block-case1} are effectively zero matrices. 

The justification why the 5 lower left block matrices are effective zero matrices in \eqref{eq-L-block-case2} in \textit{Step} 4 of case 2 is similar. 
}

\Red{This remark of justication is pretty long, but I think it makes more sense to put it here rather than an independent subsection since all three remarks in this section are justifications. Is it a good practice to include a theorem inside a remark? I skip the proof part because it's too long. What's your consideration?}
\end{remark}

\begin{remark}
{\rm 
Justifications why we're using our own CS decomposition, not 
LAPACK's CSD Algorithm -- two-phases: 
\begin{enumerate} 
\item 
The matrix is reduced to a bidiagonal block form.

\item 
The blocks are simultaneously diagonalized using techniques 
from the bidiagonal SVD algorithms.

\item Reference: 
Brian D. Sutton. 
Computing the complete CS decomposition. 
Numer. Algorithms, 50(1):33-65, 2009.
\end{enumerate} 
}
\end{remark} 
